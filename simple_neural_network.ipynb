{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6ee794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c199d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "import spacy\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1236cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"banking_data/train.csv\")\n",
    "train_data['dataset'] = \"train\"\n",
    "test_data = pd.read_csv(\"banking_data/test.csv\")\n",
    "test_data['dataset'] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e0f8a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13083, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.concat([train_data, test_data])\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0a30ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'category', 'dataset'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7881b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning the Text data\n",
    "#transform into the lower case\n",
    "data_df['text'] =  data_df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "#expanding contractions using contractions library\n",
    "data_df['text']=  data_df['text'].apply(lambda x: \" \".join(contractions.fix(x) for x in x.split()))\n",
    "\n",
    "#removing puncuation symbols\n",
    "data_df['text'] = data_df['text'].str.replace('[^\\w\\s]','',regex=True)\n",
    "\n",
    "#removing stop words\n",
    "stop = stopwords.words('english')\n",
    "data_df['text'] = data_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8a90483",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['text_old'] = data_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ab8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def pos_tag(comment):\n",
    "    doc = nlp(comment)\n",
    "    return \" \".join([token.text for token in doc if token.pos_ in  (\"VERB\",\"NOUN\",\"PRONOUN\",\"ADJ\",\"ADVERB\")])\n",
    "\n",
    "#Lemmitization function\n",
    "def space(comment):\n",
    "    doc = nlp(comment)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "#Text data\n",
    "\n",
    "## pos tag\n",
    "data_df['text'] = data_df['text'].apply(pos_tag)\n",
    "\n",
    "## lemmitization\n",
    "data_df['text']= data_df['text'].apply(space)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a41a291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_df[data_df.dataset==\"train\"].copy()\n",
    "test_df = data_df[data_df.dataset==\"test\"].copy()\n",
    "\n",
    "x_train = train_df.text.values\n",
    "y_train = train_df.category.values\n",
    "\n",
    "x_test = test_df.text.values\n",
    "y_test = test_df.category.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6623088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(x_train)\n",
    "X_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cec1904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max len: 79\n"
     ]
    }
   ],
   "source": [
    "lens_train = [len(i) for i in X_train]\n",
    "lens_test = [len(i) for i in X_test]\n",
    "lens = lens_train + lens_test\n",
    "\n",
    "maxlen = np.max(lens)\n",
    "\n",
    "print('Max len:', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7faccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45b368aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10003, 79)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f3a9faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3080, 79)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e08dd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(data_df.category)\n",
    "encoded_Y_test = encoder.transform(y_test)\n",
    "encoded_Y_train = encoder.transform(y_train)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test = np_utils.to_categorical(encoded_Y_test)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca126076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 12, 12, ..., 25, 25, 25])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "146d8fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card_arrival\n",
      "12\n",
      "12\n",
      "card_arrival\n"
     ]
    }
   ],
   "source": [
    "## check\n",
    "\n",
    "print(list(encoder.classes_)[12])\n",
    "print(list(dummy_y_test[0]).index(1))\n",
    "print(encoded_Y_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4773acc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(list(encoder.classes_))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c2c976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to regenerate results, a must must\n",
    "np.random.seed(3)\n",
    "from tensorflow.python.framework.random_seed import set_random_seed\n",
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8503525c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I -- 34\n",
    "# am -- 345\n",
    "# sleep -- 456\n",
    "# ing -- 4567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00164b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 79, 100)           239600    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 79, 100)           0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 77)                3927      \n",
      "=================================================================\n",
      "Total params: 251,127\n",
      "Trainable params: 251,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100  # vector representation of words/neuron amount after the input https://datascience.stackexchange.com/questions/53995/what-does-embedding-mean-in-machine-learning#:~:text=In%20the%20context%20of%20machine,with%20other%20models%20as%20well.\n",
    "\n",
    "model = Sequential()  # initiates the model\n",
    "model.add(layers.Embedding(input_dim=vocab_size,  # adds the first [input] layer which will be our tokenized tweets\n",
    "                          output_dim=embedding_dim,  # the embedding of that tweet, essentially inputs output\n",
    "                          input_length=maxlen))  # size of the input layer determined by maxlen calculated before\n",
    "model.add(layers.Dropout(0.2))  # dorpouts are added to help with overtraining, essentially \"turns off\" said amount of neurons before giving information to the next layer\n",
    "model.add(layers.GlobalMaxPool1D())  # https://computersciencewiki.org/index.php/Max-pooling_/_Pooling\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(50, activation='relu'))  # additional hidden layer\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(l, activation='softmax'))  # prediction layer, 2 is the number of classes we have\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f473d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "79/79 [==============================] - 4s 37ms/step - loss: 4.3262 - accuracy: 0.0224 - val_loss: 4.3146 - val_accuracy: 0.0360\n",
      "Epoch 2/3\n",
      "79/79 [==============================] - 3s 32ms/step - loss: 4.1279 - accuracy: 0.0511 - val_loss: 3.9169 - val_accuracy: 0.1130\n",
      "Epoch 3/3\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 3.4413 - accuracy: 0.1390 - val_loss: 2.9386 - val_accuracy: 0.3429\n",
      "Training Accuracy: 0.4140\n",
      "Testing Accuracy:  0.3429\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, dummy_y_train,\n",
    "                    epochs=3,  # times model will run through the data\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, dummy_y_test),\n",
    "                    batch_size=128,\n",
    "                   )  # data is set to batches we are sent to the model to predict, imagine each batc as a step in which model tries to predict the class and then checks the right answer and corrects it's weights with backpropogation\n",
    "loss, accuracy = model.evaluate(X_train, dummy_y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, dummy_y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42a46d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0df7096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predDecoded = [encoder.classes_[np.argmax(i)] for i in y_pred]  # here we get the max probability from those arrays and then based on that select which class is it.\n",
    "# cm = confusion_matrix(y_test, y_predDecoded, labels=data_df.category.unique())  # same confusion matrix code as in Logistic Regression\n",
    "# df_cm = pd.DataFrame(cm, index=data_df.category.unique(), columns=data_df.category.unique())\n",
    "# df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2741661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cm_percentage = df_cm.copy()\n",
    "# for i in df_cm_percentage:\n",
    "#     df_cm_percentage[i]/=df_cm_percentage[i].sum()\n",
    "\n",
    "# df_cm_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fa63652",
   "metadata": {},
   "outputs": [],
   "source": [
    "without text preprocessing:\n",
    "accuracy train: 41%\n",
    "accuracy test: 34%\n",
    "\n",
    "with text processing except lammitization\n",
    "accuracy train: 49%\n",
    "accuracy test: 43%\n",
    "\n",
    "with text processing with lammitization --- BEST\n",
    "accuracy train: 54%\n",
    "accuracy test: 49%\n",
    "\n",
    "with text processing with lammitization and POS tagging\n",
    "accuracy train: 52%\n",
    "accuracy test: 47%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d88eecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
